{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6e8d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /Users/brunellaquaye/Documents/yango-accra-mobility-prediction/data/raw\n",
      "Train file path: /Users/brunellaquaye/Documents/yango-accra-mobility-prediction/data/raw/Train.csv\n",
      "File exists: True\n",
      "Data loaded successfully!\n",
      "Train: (57596, 10), Test: (24684, 9)\n",
      "Weather: (744, 5), Sample: (24684, 2)\n",
      "Data loaded successfully!\n",
      "Training features shape: (57596, 8)\n",
      "Target shape: (57596,)\n",
      "Feature columns: ['destination_lat', 'destination_lon', 'lcl_start_transporting_dt', 'lcl_start_transporting_dttm', 'origin_lat', 'origin_lon', 'str_distance_km', 'transporting_distance_fact_km']\n",
      "Data loaded successfully!\n",
      "Training features shape: (57596, 8)\n",
      "Target shape: (57596,)\n",
      "Feature columns: ['destination_lat', 'destination_lon', 'lcl_start_transporting_dt', 'lcl_start_transporting_dttm', 'origin_lat', 'origin_lon', 'str_distance_km', 'transporting_distance_fact_km']\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "\n",
    "# Add project root to path (notebook-friendly approach)\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import and reload modules to ensure fresh imports\n",
    "import config\n",
    "import utils\n",
    "from scripts.feature_engineering import FeatureEngineer\n",
    "\n",
    "# Reload modules to pick up any changes\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "\n",
    "# Verify paths are correct\n",
    "print(f\"Data directory: {config.DATA_DIR}\")\n",
    "print(f\"Train file path: {config.TRAIN_FILE}\")\n",
    "print(f\"File exists: {config.TRAIN_FILE.exists()}\")\n",
    "\n",
    "# Load and clean data\n",
    "train_df, test_df,weather_df, sample_submission = utils.load_data()\n",
    "\n",
    "# Preprocessing pipelines\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Train / Val Split - using correct target column name\n",
    "X = train_df.drop(columns=['trip_id', 'Target'])  # Fixed: Target instead of travel_time\n",
    "y = train_df['Target']  # Fixed: Target instead of travel_time\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "# RMSE helper function\n",
    "rmse = lambda true, pred: np.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "print(f\"Data loaded successfully!\")\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce88bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (46076, 8)\n",
      "Validation data shape: (11520, 8)\n",
      "Categorical columns: ['lcl_start_transporting_dt', 'lcl_start_transporting_dttm']\n",
      "Numerical columns: ['destination_lat', 'destination_lon', 'origin_lat', 'origin_lon', 'str_distance_km', 'transporting_distance_fact_km']\n"
     ]
    }
   ],
   "source": [
    "# Column groups for preprocessing\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "num_pipe = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "        (\"cat\", cat_pipe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Encode training and validation data\n",
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "X_val_enc = preprocessor.transform(X_val)\n",
    "\n",
    "print(f\"Training data shape: {X_train_enc.shape}\")\n",
    "print(f\"Validation data shape: {X_val_enc.shape}\")\n",
    "print(f\"Categorical columns: {cat_cols}\")\n",
    "print(f\"Numerical columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79528a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest       RMSE: 4.6367\n",
      "Linear Regression   RMSE: 19.2243\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", rf_model)\n",
    "])\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_rmse = rmse(y_val, rf_pipe.predict(X_val))\n",
    "print(f\"Random Forest       RMSE: {rf_rmse:.4f}\")\n",
    "\n",
    "# Linear Regression Model\n",
    "lr_model = LinearRegression()\n",
    "lr_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", lr_model)\n",
    "])\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "lr_rmse = rmse(y_val, lr_pipe.predict(X_val))\n",
    "print(f\"Linear Regression   RMSE: {lr_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5623d35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1817\n",
      "[LightGBM] [Info] Number of data points in the train set: 46076, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 10.095750\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\tvalid_0's rmse: 6.30884\n",
      "[20]\tvalid_0's rmse: 5.29908\n",
      "[30]\tvalid_0's rmse: 4.93001\n",
      "[40]\tvalid_0's rmse: 4.79448\n",
      "[50]\tvalid_0's rmse: 4.7308\n",
      "[60]\tvalid_0's rmse: 4.7382\n",
      "[70]\tvalid_0's rmse: 4.74863\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's rmse: 4.72548\n",
      "LightGBM (CPU)      RMSE: 4.7255\n",
      "[40]\tvalid_0's rmse: 4.79448\n",
      "[50]\tvalid_0's rmse: 4.7308\n",
      "[60]\tvalid_0's rmse: 4.7382\n",
      "[70]\tvalid_0's rmse: 4.74863\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's rmse: 4.72548\n",
      "LightGBM (CPU)      RMSE: 4.7255\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Model\n",
    "lgb_train = lgb.Dataset(X_train_enc, label=y_train)\n",
    "lgb_val = lgb.Dataset(X_val_enc, label=y_val, reference=lgb_train)\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"num_threads\": 0,\n",
    "    \"random_state\": RANDOM_SEED\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    train_set = lgb_train,\n",
    "    valid_sets = [lgb_val],\n",
    "    num_boost_round = 500,\n",
    "    callbacks = [\n",
    "        lgb.early_stopping(stopping_rounds=20),\n",
    "        lgb.log_evaluation(period=10)\n",
    "    ]\n",
    ")\n",
    "lgb_rmse = rmse(y_val, lgb_model.predict(X_val_enc, num_iteration=lgb_model.best_iteration))\n",
    "print(f\"LightGBM (CPU)      RMSE: {lgb_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost (CPU)       RMSE: 4.8375\n",
      "\n",
      "RMSE summary: {'Random Forest': '4.6367', 'Linear Regression': '19.2243', 'LightGBM (CPU)': '4.7255', 'XGBoost (CPU)': '4.8375'}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost Model\n",
    "dtrain = xgb.DMatrix(X_train_enc, label=y_train)\n",
    "dval = xgb.DMatrix(X_val_enc, label=y_val)\n",
    "\n",
    "\n",
    "\n",
    "# Include the early_stopping_round in the method and not the model.fit due to the version of xgb model being used\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    n_jobs=0,\n",
    "    random_state=RANDOM_SEED,\n",
    "    early_stopping_rounds=30,\n",
    "    eval_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "# Fit without callbacks parameter\n",
    "xgb_model.fit(\n",
    "    X_train_enc,\n",
    "    y_train,\n",
    "    eval_set=[(X_val_enc, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "xgb_rmse = rmse(y_val, xgb_model.predict(X_val_enc))\n",
    "print(f\"XGBoost (CPU)       RMSE: {xgb_rmse:.4f}\")\n",
    "\n",
    "# Model comparison\n",
    "rmse_scores = {\n",
    "    \"Random Forest\": rf_rmse,\n",
    "    \"Linear Regression\": lr_rmse,\n",
    "    \"LightGBM (CPU)\": lgb_rmse,\n",
    "    \"XGBoost (CPU)\": xgb_rmse\n",
    "}\n",
    "\n",
    "print(\"\\nRMSE summary:\", {k: f\"{v:.4f}\" for k, v in rmse_scores.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55a7a4",
   "metadata": {},
   "source": [
    "<!-- # Model Training Notebook\n",
    "\n",
    "This notebook is dedicated to training machine learning models for the Yango Accra Mobility Prediction Hackathon. The goal is to predict ride times using trip and weather data.\n",
    "\n",
    "**Key Steps:**\n",
    "1. Import required libraries\n",
    "2. Load and preprocess data\n",
    "3. Train-test split\n",
    "4. Train baseline models\n",
    "5. Train advanced models (e.g., LightGBM, XGBoost)\n",
    "6. Evaluate models using RMSE\n",
    "7. Save the best model -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f437df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Random Forest\n",
      "Best RMSE: 4.6367\n",
      "Selected model object: <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "best_model = min(rmse_scores, key=rmse_scores.get)\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best RMSE: {rmse_scores[best_model]:.4f}\")\n",
    "\n",
    "# Save the best model - use the correct model objects\n",
    "best_model_obj = None\n",
    "if best_model == \"Random Forest\":\n",
    "    best_model_obj = rf_pipe  # Use the pipeline, not just rf_model\n",
    "elif best_model == \"Linear Regression\": \n",
    "    best_model_obj = lr_pipe  # Use the pipeline, not just lr_model\n",
    "elif best_model == \"LightGBM (CPU)\":\n",
    "    best_model_obj = lgb_model\n",
    "elif best_model == \"XGBoost (CPU)\":\n",
    "    best_model_obj = xgb_model\n",
    "\n",
    "print(f\"Selected model object: {type(best_model_obj)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4926d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file saved to: /Users/brunellaquaye/Documents/yango-accra-mobility-prediction/outputs/submission.csv\n",
      "Submission shape: (24684, 2)\n",
      "\n",
      "First 5 predictions:\n",
      "         trip_id  travel_time\n",
      "0  ID_PV4QVE2H2X     4.582467\n",
      "1  ID_SUOBMO2E7V     7.763400\n",
      "2  ID_Q5KSL38U9B    15.543367\n",
      "3  ID_1G08NWYA35    27.140967\n",
      "4  ID_H7IZ8JL8YT     8.282500\n"
     ]
    }
   ],
   "source": [
    "# Generate submission file using the best model\n",
    "# Prepare test data\n",
    "X_test = test_df.drop(columns=['trip_id'])\n",
    "\n",
    "# Make predictions - handle both pipeline and direct models\n",
    "if best_model in [\"Random Forest\", \"Linear Regression\"]:\n",
    "    # For pipeline models (RF and LR), use raw data\n",
    "    test_predictions = best_model_obj.predict(X_test)\n",
    "else:\n",
    "    # For direct models (LightGBM and XGBoost), use encoded data\n",
    "    X_test_enc = preprocessor.transform(X_test)\n",
    "    if best_model == \"LightGBM (CPU)\":\n",
    "        test_predictions = best_model_obj.predict(X_test_enc, num_iteration=lgb_model.best_iteration)\n",
    "    else:  # XGBoost\n",
    "        test_predictions = best_model_obj.predict(X_test_enc)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'trip_id': test_df['trip_id'],\n",
    "    'travel_time': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission_path = config.PROJECT_ROOT / \"outputs\" / \"submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission file saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission.shape}\")\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1uHOfbuNWDJ"
      },
      "source": [
        "# Yango Accra Mobility Prediction - Starter Notebook\n",
        "\n",
        "This notebook provides a baseline implementation for the Yango Accra Mobility Prediction challenge.\n",
        "\n",
        "## Objective\n",
        "Predict ride travel times in Accra, Ghana using trip data and weather conditions.\n",
        "\n",
        "## Dataset\n",
        "- Training data: 57,596 trips\n",
        "- Test data: 24,686 trips  \n",
        "- Weather data: Hourly weather information for May 2024\n",
        "- Target variable: Trip duration in minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YMt3I2pgP76M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing data files: ['Train.csv', 'Test.csv', 'Accra_weather.csv', 'SampleSubmission.csv', 'VariableDefinitions.csv']\n",
            "Please place data files in: c:\\Users\\CALYX BLAY\\OneDrive\\Desktop\\yango-accra-mobility-prediction\\data\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('.'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import config\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Check if data files exist\n",
        "config.check_data_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J2DhGqHpQkhk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random seed set to: 42\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "import random\n",
        "SEED = config.RANDOM_SEED\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "print(f\"Random seed set to: {SEED}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro-KRpqn5pbB"
      },
      "source": [
        "## Data Loading and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EX2hr8mGQruk"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\CALYX BLAY\\\\OneDrive\\\\Desktop\\\\yango-accra-mobility-prediction\\\\data\\\\Train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load data files using config paths\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(config\u001b[38;5;241m.\u001b[39mTEST_FILE)\n\u001b[0;32m      4\u001b[0m samplesubmission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(config\u001b[38;5;241m.\u001b[39mSAMPLE_SUBMISSION_FILE)\n",
            "File \u001b[1;32mc:\\Users\\CALYX BLAY\\OneDrive\\Desktop\\yango-accra-mobility-prediction\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\CALYX BLAY\\OneDrive\\Desktop\\yango-accra-mobility-prediction\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\CALYX BLAY\\OneDrive\\Desktop\\yango-accra-mobility-prediction\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\CALYX BLAY\\OneDrive\\Desktop\\yango-accra-mobility-prediction\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\CALYX BLAY\\OneDrive\\Desktop\\yango-accra-mobility-prediction\\.venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\CALYX BLAY\\\\OneDrive\\\\Desktop\\\\yango-accra-mobility-prediction\\\\data\\\\Train.csv'"
          ]
        }
      ],
      "source": [
        "# Load data files using config paths\n",
        "train = pd.read_csv(config.TRAIN_FILE)\n",
        "test = pd.read_csv(config.TEST_FILE)\n",
        "samplesubmission = pd.read_csv(config.SAMPLE_SUBMISSION_FILE)\n",
        "weather_df = pd.read_csv(config.WEATHER_FILE, index_col=0)\n",
        "variable_def = pd.read_csv(config.VARIABLE_DEFINITIONS_FILE)\n",
        "\n",
        "print(\"Data files loaded successfully!\")\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test shape: {test.shape}\")\n",
        "print(f\"Weather shape: {weather_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "1p0IORz3pG1L",
        "outputId": "b24c6fcf-81b5-4f48-9b11-b725d911a041"
      },
      "outputs": [],
      "source": [
        "variable_def"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "wY-QM-6Jc3gB",
        "outputId": "a9223ca9-e0fd-455b-b2e6-ed3fc332ebca"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "aizfGRd6c5bW",
        "outputId": "23eb9526-fc47-4502-f1d1-b5c3b6ae9c9a"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ditPO4DMc7st",
        "outputId": "80518b1a-3c07-4a45-916c-e60861fadec0"
      },
      "outputs": [],
      "source": [
        "samplesubmission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "WsQvXHmdc9u2",
        "outputId": "9fe5aa58-fa60-47bb-9ae3-9c146374b8ec"
      },
      "outputs": [],
      "source": [
        "weather_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag0lQcSuTrfZ"
      },
      "outputs": [],
      "source": [
        "def extract_datetime_features(data, cols: list):\n",
        "    df = data.copy()\n",
        "    for col in cols:\n",
        "        df[col] = pd.to_datetime(df[col])\n",
        "        df[f'{col}_hour'] = df[col].dt.hour\n",
        "        df[f'{col}_day'] = df[col].dt.day\n",
        "        df[f'{col}_month'] = df[col].dt.month\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "J_SKQjDCSTwh",
        "outputId": "3d21c9ee-f6b7-4c61-fc87-9300395eae39"
      },
      "outputs": [],
      "source": [
        "# extract datetime features\n",
        "train = extract_datetime_features(train, ['lcl_start_transporting_dttm'])\n",
        "test = extract_datetime_features(test, ['lcl_start_transporting_dttm'])\n",
        "weather_df = extract_datetime_features(weather_df, ['lcl_datetime'])\n",
        "\n",
        "# Preview train dataset\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "zOBgdgcPRTje",
        "outputId": "4f18e32a-8a3c-41a3-fa72-ec775c030fa4"
      },
      "outputs": [],
      "source": [
        "# Preview test dataset\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h3CsH4JkRQwt",
        "outputId": "c5a14209-a0cd-48d6-901e-c72cdb83bd2c"
      },
      "outputs": [],
      "source": [
        "# Preview sample submission file\n",
        "samplesubmission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "uM8nA_t9RVcc",
        "outputId": "e26e3b84-97bd-4268-860e-e9bc7128e939"
      },
      "outputs": [],
      "source": [
        "# Preview graph data\n",
        "weather_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRLIKYLiRY1Q",
        "outputId": "b48a2f98-f73c-4fb2-fdb1-a7fb994b9c9d"
      },
      "outputs": [],
      "source": [
        "# Check size and shape of datasets\n",
        "train.shape, test.shape, samplesubmission.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkRxj0NZRa3K",
        "outputId": "318459dd-55b2-445d-a71c-5c6ab07249d9"
      },
      "outputs": [],
      "source": [
        "# Train to test sets ratio\n",
        "(test.shape[0]) / (train.shape[0] + test.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNtwMcKjZk9x"
      },
      "source": [
        "## Statistical Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "NNmTMedHRcEa",
        "outputId": "30fbafbb-14cc-407b-dc57-29e61c678123"
      },
      "outputs": [],
      "source": [
        "# Training data statistical summary\n",
        "train.describe(include='number')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kESZ-qvnSEa"
      },
      "source": [
        "### Key Insights\n",
        "\n",
        "- Training dataset contains 57,596 trip records\n",
        "- Average trip duration: 10.08 minutes\n",
        "- Trip duration range: 1.02 to 585.93 minutes (outliers present)\n",
        "- Strong variation in trip characteristics suggests good prediction potential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "P3AlXynlXziW",
        "outputId": "55046dd3-71a1-4110-d1fa-0fb6cb4020ce"
      },
      "outputs": [],
      "source": [
        "# Target variable distribution\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(train.Target, bins=50)\n",
        "plt.title('Target Variable Distribution', fontsize=14)\n",
        "plt.xlabel('Trip Duration (minutes)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Skewness: {train.Target.skew():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4gly1_uSAeY"
      },
      "source": [
        "**Observation**: The target variable is right-skewed, indicating most trips are short with some very long trips (outliers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ6dymKo_VXp"
      },
      "source": [
        "## Outlier Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "N8d1_h8_RhCP",
        "outputId": "8fb079f5-a8ca-4af0-a16f-67fddb4b9b25"
      },
      "outputs": [],
      "source": [
        "# Boxplot for outlier detection\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=train.Target)\n",
        "plt.title('Trip Duration Outliers', fontsize=14)\n",
        "plt.xlabel('Trip Duration (minutes)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvtoMmLdak_z"
      },
      "source": [
        "### Outlier Handling Strategies\n",
        "\n",
        "Outliers are data points that differ significantly from other observations.\n",
        "\n",
        "**Potential approaches:**\n",
        "- **Transformation**: Log transformation, Box-Cox transformation\n",
        "- **Trimming**: Remove extreme outliers (e.g., >99th percentile)\n",
        "- **Capping**: Cap extreme values at reasonable thresholds\n",
        "- **Robust models**: Use models less sensitive to outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q2YustL_ZG7"
      },
      "source": [
        "## Weather Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuj8QfY6hDvN",
        "outputId": "f33f461d-3dae-4e9e-bf80-91aeb3777ddd"
      },
      "outputs": [],
      "source": [
        "weather_df.lcl_datetime.min(), weather_df.lcl_datetime.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "bVcOYAgMYjji",
        "outputId": "4a36f5fb-8db4-4677-fe05-de5e5c868772"
      },
      "outputs": [],
      "source": [
        "weather_df.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNt15VEaZjPQ"
      },
      "source": [
        "### Weather Insights\n",
        "\n",
        "- **Precipitation**: Average 0.151mm, maximum 4.34mm in May 2024\n",
        "- **Temperature**: Average 28.30°C, range 25.92-30.49°C\n",
        "- **Coverage**: Hourly data available for entire month\n",
        "- **Impact**: Weather conditions likely affect trip duration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgvLRzJpbPaK"
      },
      "source": [
        "### Merging Trip and Weather Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "R994xR9LiRe8",
        "outputId": "b7a7917f-ccc3-4286-a3b7-3469564922fb"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_hufi5lbT2v"
      },
      "outputs": [],
      "source": [
        "# Create day_hour variable for merging\n",
        "train['day_hour'] = (train['lcl_start_transporting_dttm_day'].astype(str).str.split('.').str[0] + \n",
        "                    '_' + train['lcl_start_transporting_dttm_hour'].astype(str).str.split('.').str[0])\n",
        "\n",
        "test['day_hour'] = (test['lcl_start_transporting_dttm_day'].astype(str).str.split('.').str[0] + \n",
        "                   '_' + test['lcl_start_transporting_dttm_hour'].astype(str).str.split('.').str[0])\n",
        "\n",
        "weather_df['day_hour'] = (weather_df['lcl_datetime_day'].astype(str).str.split('.').str[0] + \n",
        "                         '_' + weather_df['lcl_datetime_hour'].astype(str).str.split('.').str[0])\n",
        "\n",
        "print(\"Merge keys created successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qSvvTwDaWtJ"
      },
      "outputs": [],
      "source": [
        "# Merge weather data with trip data\n",
        "train_before = train.shape[0]\n",
        "test_before = test.shape[0]\n",
        "\n",
        "train = train.merge(weather_df, on='day_hour', how='left')\n",
        "test = test.merge(weather_df, on='day_hour', how='left')\n",
        "\n",
        "print(f\"Train records: {train_before} -> {train.shape[0]}\")\n",
        "print(f\"Test records: {test_before} -> {test.shape[0]}\")\n",
        "print(\"Weather data merged successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "PSfe6HVXiz5a",
        "outputId": "a93c58f1-c348-462e-cdd3-2f449a424eaa"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "_eGGrpIui6h5",
        "outputId": "db9c167a-ea0d-40f7-ad7d-2e0742f9b3a1"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJNhVNKn5uEE"
      },
      "source": [
        "## Data Quality Assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Iw1aSYrccq6",
        "outputId": "12257fff-ddd3-4598-fb57-2049220c1abb"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "train_missing = train.isnull().sum()\n",
        "test_missing = test.isnull().sum()\n",
        "\n",
        "print(\"Missing values in train data:\")\n",
        "print(train_missing[train_missing > 0])\n",
        "print(\"\\nMissing values in test data:\")\n",
        "print(test_missing[test_missing > 0])\n",
        "\n",
        "print(f\"\\nOverall missing data: Train={train.isnull().sum().any()}, Test={test.isnull().sum().any()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e06doaah27vk"
      },
      "source": [
        "### Missing Value Handling Strategies\n",
        "\n",
        "- **Numerical features**: Fill with median/mean values\n",
        "- **Categorical features**: Fill with mode or create \"unknown\" category  \n",
        "- **Weather data**: Forward/backward fill for temporal continuity\n",
        "- **Complete case analysis**: Drop rows with missing target values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnAfndzp6Otn",
        "outputId": "66221dd1-f354-4ca0-8aa9-b9a6e083a519"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate records\n",
        "train_duplicates = train.duplicated().sum()\n",
        "test_duplicates = test.duplicated().sum()\n",
        "\n",
        "print(f\"Duplicate records:\")\n",
        "print(f\"Train: {train_duplicates}\")\n",
        "print(f\"Test: {test_duplicates}\")\n",
        "\n",
        "# Check for duplicate trip IDs\n",
        "train_id_duplicates = train['trip_id'].duplicated().sum()\n",
        "test_id_duplicates = test['trip_id'].duplicated().sum()\n",
        "\n",
        "print(f\"\\nDuplicate trip IDs:\")\n",
        "print(f\"Train: {train_id_duplicates}\")\n",
        "print(f\"Test: {test_id_duplicates}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9O2HykxLwcJ"
      },
      "source": [
        "## Feature Correlation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "9qvzT3B56R2l",
        "outputId": "e3dd5a68-6b6d-447e-d300-8516fba1cd8e"
      },
      "outputs": [],
      "source": [
        "# Calculate correlations with target variable\n",
        "numeric_features = train.select_dtypes(include='number')\n",
        "target_correlations = abs(numeric_features.corr()['Target']).sort_values(ascending=False)\n",
        "\n",
        "print(\"Top 15 features correlated with target:\")\n",
        "print(target_correlations.head(15))\n",
        "\n",
        "# Display as DataFrame for better formatting\n",
        "correlation_df = pd.DataFrame({\n",
        "    'Feature': target_correlations.head(15).index,\n",
        "    'Correlation': target_correlations.head(15).values\n",
        "})\n",
        "correlation_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J-6L_Ihb6Wrk",
        "outputId": "d0ead21e-b71c-4a75-9b8c-adfb00d42834"
      },
      "outputs": [],
      "source": [
        "# Select key features for correlation analysis\n",
        "key_features = ['destination_lat', 'destination_lon', 'origin_lat', 'origin_lon',\n",
        "               'str_distance_km', 'transporting_distance_fact_km', \n",
        "               'lcl_start_transporting_dttm_day', 'lcl_start_transporting_dttm_month', \n",
        "               'prev_hour_precipitation_mm', 'temperature_C', 'Target']\n",
        "\n",
        "# Create correlation matrix\n",
        "correlation_matrix = train[key_features].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
        "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
        "plt.title('Feature Correlation Matrix', fontsize=16, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gIDFBaMs8fk"
      },
      "source": [
        "## Baseline Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsmtpdMu7Crk",
        "outputId": "2563bd34-7f6b-430f-e70f-87aa8aee4563"
      },
      "outputs": [],
      "source": [
        "# Select features for baseline model\n",
        "feature_cols = ['str_distance_km', 'temperature_C', 'transporting_distance_fact_km',\n",
        "               'lcl_start_transporting_dttm_day', 'prev_hour_precipitation_mm']\n",
        "\n",
        "# Prepare feature matrix and target\n",
        "X = train[feature_cols].fillna(0)\n",
        "y = train[config.TARGET_COLUMN]\n",
        "\n",
        "print(f\"Features selected: {len(feature_cols)}\")\n",
        "print(f\"Training samples: {len(X)}\")\n",
        "print(f\"Features: {feature_cols}\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
        "\n",
        "# Train Random Forest model\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=SEED, \n",
        "    n_jobs=-1,\n",
        "    max_depth=10\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse_score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "print(f'\\nBaseline RMSE: {rmse_score:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "SICL6RDX8K7B",
        "outputId": "0436d4d6-2054-450a-8008-db96a5ae5b1a"
      },
      "outputs": [],
      "source": [
        "# Feature importance analysis\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=True)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
        "plt.title('Feature Importance (Random Forest)', fontsize=14)\n",
        "plt.xlabel('Importance Score')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display importance values\n",
        "print(\"Feature Importance Rankings:\")\n",
        "for idx, row in feature_importance.iterrows():\n",
        "    print(f\"{row['feature']}: {row['importance']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UuShmECwAbL"
      },
      "source": [
        "## Generate Predictions and Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lUel_76z8taS",
        "outputId": "d5f6b371-d5b6-492e-bdbc-c2edff454d50"
      },
      "outputs": [],
      "source": [
        "# Prepare test data for prediction\n",
        "test_features = test[feature_cols].fillna(0)\n",
        "\n",
        "# Generate predictions\n",
        "test_predictions = model.predict(test_features)\n",
        "\n",
        "# Create submission dataframe\n",
        "submission = pd.DataFrame({\n",
        "    'trip_id': test['trip_id'],\n",
        "    'Target': test_predictions\n",
        "})\n",
        "\n",
        "print(f\"Predictions generated for {len(submission)} test samples\")\n",
        "print(f\"Prediction range: {test_predictions.min():.2f} to {test_predictions.max():.2f}\")\n",
        "print(\"\\nFirst 10 predictions:\")\n",
        "submission.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3br7aoi8zR3"
      },
      "outputs": [],
      "source": [
        "# Save submission file\n",
        "submission_path = config.get_output_path('baseline_submission.csv')\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"Submission file saved to: {submission_path}\")\n",
        "print(f\"File size: {len(submission)} rows\")\n",
        "\n",
        "# Verify submission format\n",
        "print(\"\\nSubmission file format verification:\")\n",
        "print(f\"Columns: {list(submission.columns)}\")\n",
        "print(f\"Sample verification passed: {list(submission.columns) == ['trip_id', 'Target']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_BBwmW05HAR"
      },
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "### Baseline Results\n",
        "- **Model**: Random Forest with 5 features\n",
        "- **Validation RMSE**: ~4.4 minutes\n",
        "- **Key Features**: Distance measures and weather conditions\n",
        "\n",
        "### Potential Improvements\n",
        "1. **Feature Engineering**: Add time-based, geographical, and interaction features\n",
        "2. **Advanced Models**: Try LightGBM, XGBoost, or ensemble methods\n",
        "3. **Hyperparameter Tuning**: Optimize model parameters\n",
        "4. **Data Preprocessing**: Handle outliers and missing values more sophisticated\n",
        "5. **Cross-Validation**: Use proper CV strategy for robust evaluation\n",
        "\n",
        "### Next Notebooks\n",
        "- `01_eda_and_cleaning.ipynb`: Detailed exploratory analysis\n",
        "- `02_train_model.ipynb`: Advanced modeling techniques\n",
        "\n",
        "Good luck with the competition!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
